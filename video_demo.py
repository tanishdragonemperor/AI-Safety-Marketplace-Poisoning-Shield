#!/usr/bin/env python3
"""
VIDEO RECORDING DEMO SCRIPT
============================
Run this while screen recording for your AI Safety class presentation.

Usage: python video_demo.py

This script pauses at each step so you can explain what's happening.
Press ENTER to continue to the next section.
"""

import sys
import os
import time
import copy

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from dataset_generator import MarketplaceDatasetGenerator
from attack_simulator import AttackSimulator
from defense_module import MarketplaceDefender
from search_pipeline import MarketplaceSearchPipeline


def slow_print(text, delay=0.02):
    """Print text with typewriter effect."""
    for char in text:
        print(char, end='', flush=True)
        time.sleep(delay)
    print()


def section_break(title):
    """Display a clear section break."""
    print("\n")
    print("=" * 70)
    print(f"   {title}")
    print("=" * 70)
    input("\n   [Press ENTER to continue...]\n")


def main():
    # =========================================================================
    # INTRO
    # =========================================================================
    os.system('clear' if os.name != 'nt' else 'cls')
    
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                                       â•‘
    â•‘          MARKETPLACE POISONING SHIELD                                 â•‘
    â•‘                                                                       â•‘
    â•‘          Detecting and Defending Against Silent Data                  â•‘
    â•‘          Poisoning in AI-Powered Marketplaces                         â•‘
    â•‘                                                                       â•‘
    â•‘          Project by: Tanish Gupta                                     â•‘
    â•‘          Course: Intro to AI Security                                 â•‘
    â•‘                                                                       â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("""
    ğŸ“‹ PROJECT OVERVIEW
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    This project addresses a critical AI security vulnerability:
    
    Modern e-commerce platforms like Amazon, eBay, and Alibaba use AI for:
      â€¢ Search ranking and product discovery
      â€¢ Recommendation systems
      â€¢ Review analysis and fraud detection
      â€¢ Content moderation
    
    THE PROBLEM: These AI systems learn from USER-PROVIDED DATA.
    
    Attackers can inject POISONED DATA that:
      âœ— Manipulates search rankings (their products appear first)
      âœ— Boosts fraudulent listings
      âœ— Evades content moderation
      âœ— Bypasses fraud detection
    
    The attacks are SILENT - invisible to human moderators!
    
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """)
    
    section_break("PART 1: UNDERSTANDING THE THREAT")
    
    # =========================================================================
    # PART 1: THE THREAT
    # =========================================================================
    
    print("""
    ğŸ” PART 1: UNDERSTANDING SILENT DATA POISONING
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Let me show you how these invisible attacks work...
    """)
    
    print("\n    EXAMPLE 1: Hidden Character Injection")
    print("    " + "â”€" * 50)
    
    clean_text = "Premium Wireless Headphones"
    poisoned_text = "Premium\u200b Wireless\u200b Headphones"
    
    print(f"""
    Clean text:    "{clean_text}"
    Poisoned text: "{poisoned_text}"
    
    They look IDENTICAL, right?
    
    But let's check the bytes:
    """)
    
    time.sleep(1)
    
    print(f"    Clean bytes:    {len(clean_text.encode())} bytes")
    print(f"    Poisoned bytes: {len(poisoned_text.encode())} bytes")
    print(f"    Difference:     +{len(poisoned_text.encode()) - len(clean_text.encode())} hidden bytes!")
    
    print("""
    
    Those extra bytes are ZERO-WIDTH CHARACTERS (\\u200b)
    - Invisible to humans
    - But AI tokenizers see them differently
    - This can manipulate embeddings and search rankings!
    """)
    
    input("\n    [Press ENTER to see more attack types...]\n")
    
    print("""
    EXAMPLE 2: Homoglyph Attack (Character Substitution)
    """ + "â”€" * 50)
    
    print("""
    Original: "Premium" (Latin alphabet)
    Poisoned: "PrĞµmium" (with Cyrillic 'Ğµ')
    
    The Cyrillic 'Ğµ' (U+0435) looks identical to Latin 'e' (U+0065)
    But they have different Unicode code points!
    
    This tricks AI systems that rely on exact text matching.
    """)
    
    section_break("PART 2: DATASET GENERATION")
    
    # =========================================================================
    # PART 2: DATASET
    # =========================================================================
    
    print("""
    ğŸ“¦ PART 2: SYNTHETIC DATASET GENERATION
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    First, I created a realistic e-commerce dataset generator.
    
    Let me generate some sample products...
    """)
    
    time.sleep(1)
    
    generator = MarketplaceDatasetGenerator(seed=42)
    products = generator.generate_dataset(size=100)
    
    print(f"""
    âœ… Generated {len(products)} products
    
    Categories: electronics, clothing, home, sports, beauty
    
    Sample products:
    """)
    
    for i, p in enumerate(products[:5]):
        print(f"    {i+1}. {p.title}")
        print(f"       Category: {p.category} | Price: ${p.price} | Rating: {p.rating}â­")
        print()
    
    print("""
    Each product has:
      â€¢ Title and description
      â€¢ Category and price
      â€¢ Seller information
      â€¢ Reviews with ratings
      â€¢ Metadata (keywords, shipping, etc.)
    """)
    
    section_break("PART 3: ATTACK SIMULATION (RED TEAM)")
    
    # =========================================================================
    # PART 3: ATTACKS
    # =========================================================================
    
    print("""
    âš”ï¸  PART 3: ATTACK SIMULATION (RED TEAM)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Now I'll demonstrate each attack type on a sample product.
    
    I implemented 6 different attack types:
    """)
    
    attacker = AttackSimulator(seed=42)
    sample = products[0]
    
    print(f"""
    ğŸ“¦ TARGET PRODUCT:
       Title: {sample.title}
       Description: {sample.description[:60]}...
       Rating: {sample.rating}â­
       Reviews: {sample.review_count}
    """)
    
    input("\n    [Press ENTER to run Attack #1: Hidden Characters...]\n")
    
    # Attack 1
    print("    ATTACK 1: HIDDEN CHARACTER INJECTION")
    print("    " + "â”€" * 50)
    
    original = copy.deepcopy(sample)
    poisoned = attacker.inject_hidden_characters(original, intensity=0.4)
    
    print(f"""
    Original title: "{original.title}"
    Poisoned title: "{poisoned.title}"
    
    Bytes before: {len(original.title.encode())}
    Bytes after:  {len(poisoned.title.encode())}
    Hidden chars: {len(poisoned.title.encode()) - len(original.title.encode())}
    
    âš ï¸  The poisoned text looks identical but contains invisible characters
       that can manipulate AI embeddings!
    """)
    
    input("\n    [Press ENTER for Attack #2: Keyword Stuffing...]\n")
    
    # Attack 2
    print("    ATTACK 2: KEYWORD STUFFING")
    print("    " + "â”€" * 50)
    
    original = copy.deepcopy(sample)
    poisoned = attacker.stuff_keywords(original, keyword_count=10)
    
    print(f"""
    Original description:
    "{original.description[:80]}..."
    
    Poisoned description:
    "{poisoned.description[:120]}..."
    
    âš ï¸  SEO spam keywords are injected to artificially boost search rankings!
    """)
    
    input("\n    [Press ENTER for Attack #3: Fake Reviews...]\n")
    
    # Attack 3
    print("    ATTACK 3: FAKE REVIEW INJECTION")
    print("    " + "â”€" * 50)
    
    original = copy.deepcopy(sample)
    poisoned = attacker.inject_fake_reviews(original, fake_count=5, boost_rating=True)
    
    print(f"""
    Original rating: {original.rating}â­ ({original.review_count} reviews)
    Boosted rating:  {poisoned.rating}â­ ({poisoned.review_count} reviews)
    
    Fake reviews injected:
    """)
    
    for review in poisoned.reviews[:3]:
        if review.get('is_fake'):
            print(f'    â˜…â˜…â˜…â˜…â˜… "{review["text"][:50]}..."')
    
    print("""
    âš ï¸  Fake 5-star reviews artificially inflate the product rating!
    """)
    
    input("\n    [Press ENTER for Attack #4: Homoglyph...]\n")
    
    # Attack 4
    print("    ATTACK 4: HOMOGLYPH ATTACK")
    print("    " + "â”€" * 50)
    
    original = copy.deepcopy(sample)
    poisoned = attacker.apply_homoglyphs(original, replacement_rate=0.3)
    
    print(f"""
    Original: "{original.title}"
    Poisoned: "{poisoned.title}"
    
    Characters replaced: Latin â†’ Cyrillic/Greek lookalikes
    
    Examples of homoglyphs used:
      â€¢ 'a' â†’ 'Ğ°' (Cyrillic)
      â€¢ 'e' â†’ 'Ğµ' (Cyrillic)  
      â€¢ 'o' â†’ 'Ğ¾' (Cyrillic)
      â€¢ 'p' â†’ 'Ñ€' (Cyrillic)
    
    âš ï¸  Text looks identical but has different character codes!
    """)
    
    input("\n    [Press ENTER to poison the full dataset...]\n")
    
    # Poison dataset
    print("    POISONING THE FULL DATASET")
    print("    " + "â”€" * 50)
    
    poisoned_products, attack_stats = attacker.poison_dataset(products, poison_rate=0.25)
    
    print(f"""
    Dataset size: {attack_stats['total']} products
    Poisoned:     {attack_stats['poisoned']} products ({attack_stats['poisoned']/attack_stats['total']*100:.0f}%)
    Clean:        {attack_stats['clean']} products
    
    Attack distribution:
    """)
    
    for attack_type, count in attack_stats['attack_counts'].items():
        bar = "â–ˆ" * (count * 3) + "â–‘" * (15 - count * 3)
        print(f"      {attack_type:25s} [{bar}] {count}")
    
    section_break("PART 4: DEFENSE SYSTEM (BLUE TEAM)")
    
    # =========================================================================
    # PART 4: DEFENSE
    # =========================================================================
    
    print("""
    ğŸ›¡ï¸  PART 4: DEFENSE SYSTEM (BLUE TEAM)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    I implemented a MULTI-LAYER defense system with 6 detection layers:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  LAYER 1: Unicode Anomaly Detection                                 â”‚
    â”‚           â†’ Scans for zero-width and hidden characters              â”‚
    â”‚           â†’ Flags suspicious Unicode categories                     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  LAYER 2: Keyword Density Analysis                                  â”‚
    â”‚           â†’ Detects SEO spam patterns                               â”‚
    â”‚           â†’ Analyzes word repetition frequency                      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  LAYER 3: Homoglyph Detection                                       â”‚
    â”‚           â†’ Maps 50+ known character substitutions                  â”‚
    â”‚           â†’ Calculates substitution ratio                           â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  LAYER 4: Review Authenticity Checker                               â”‚
    â”‚           â†’ Pattern matching for fake reviews                       â”‚
    â”‚           â†’ Sentiment and helpfulness analysis                      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  LAYER 5: Metadata Validation                                       â”‚
    â”‚           â†’ Detects hidden fields                                   â”‚
    â”‚           â†’ Validates metric plausibility                           â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  LAYER 6: Statistical Anomaly Detection                             â”‚
    â”‚           â†’ Compares against baseline statistics                    â”‚
    â”‚           â†’ Z-score calculation for outliers                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    This is called "DEFENSE IN DEPTH" - no single layer catches everything,
    but together they provide robust protection!
    """)
    
    input("\n    [Press ENTER to run the defense analysis...]\n")
    
    print("    RUNNING DEFENSE ANALYSIS...")
    print("    " + "â”€" * 50)
    print()
    
    defender = MarketplaceDefender()
    defender.build_baseline(products)  # Learn what "normal" looks like
    
    results, summary = defender.analyze_dataset(poisoned_products)
    
    print(f"""
    âœ… Analysis complete!
    
    Products analyzed: {summary['total_analyzed']}
    Flagged as suspicious: {summary['suspicious_found']}
    Detection rate: {summary['detection_rate']*100:.1f}%
    Average threat score: {summary['avg_threat_score']:.3f}
    """)
    
    print("    Sample detections:")
    print("    " + "â”€" * 50)
    
    detected_count = 0
    for p, r in zip(poisoned_products, results):
        if p.is_poisoned and detected_count < 6:
            status = "âœ… DETECTED" if r.is_suspicious else "âŒ MISSED"
            print(f"      {p.poison_type:25s} | Threat: {r.threat_score:.2f} | {status}")
            detected_count += 1
    
    section_break("PART 5: SEARCH IMPACT DEMONSTRATION")
    
    # =========================================================================
    # PART 5: SEARCH IMPACT
    # =========================================================================
    
    print("""
    ğŸ” PART 5: SEARCH IMPACT DEMONSTRATION
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    This is the key insight: How does poisoning affect REAL USERS?
    
    I built a semantic search pipeline using embeddings + vector similarity
    to simulate how marketplace search works.
    
    Let's compare search results WITH and WITHOUT defense...
    """)
    
    input("\n    [Press ENTER to build search index...]\n")
    
    print("    Building search index...")
    
    pipeline = MarketplaceSearchPipeline(use_neural_embeddings=False)
    pipeline.set_defender(defender)
    pipeline.index_products(poisoned_products, with_defense=True)
    
    print(f"    âœ… Indexed {pipeline.index.size()} products")
    print()
    
    queries = ["premium quality", "best headphones", "top rated"]
    
    for query in queries:
        print(f"\n    SEARCH: \"{query}\"")
        print("    " + "â”€" * 50)
        
        comparison = pipeline.compare_search(query, k=5)
        
        print("\n    WITHOUT DEFENSE (vulnerable):")
        for r in comparison["baseline"]["results"][:5]:
            marker = "ğŸ”´ POISONED" if r.is_poisoned else "ğŸŸ¢ Clean"
            print(f"      {r.rank}. {r.product.title[:35]:35s} | {marker}")
        print(f"      â†’ Poisoned in top 5: {comparison['baseline']['poisoned_in_top_5']}")
        
        print("\n    WITH DEFENSE (protected):")
        for r in comparison["defended"]["results"][:5]:
            marker = "ğŸ”´ POISONED" if r.is_poisoned else "ğŸŸ¢ Clean"
            print(f"      {r.rank}. {r.product.title[:35]:35s} | {marker}")
        print(f"      â†’ Poisoned in top 5: {comparison['defended']['poisoned_in_top_5']}")
        
        blocked = comparison['baseline']['poisoned_in_top_5'] - comparison['defended']['poisoned_in_top_5']
        print(f"\n      âœ¨ Defense blocked {blocked} poisoned products!")
        
        input("\n    [Press ENTER for next search...]\n")
    
    section_break("PART 6: EVALUATION METRICS")
    
    # =========================================================================
    # PART 6: EVALUATION
    # =========================================================================
    
    print("""
    ğŸ“Š PART 6: EVALUATION METRICS
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    How do we measure defense effectiveness?
    
    I use standard ML classification metrics:
    """)
    
    # Calculate metrics
    tp = sum(1 for p, r in zip(poisoned_products, results) if p.is_poisoned and r.is_suspicious)
    fp = sum(1 for p, r in zip(poisoned_products, results) if not p.is_poisoned and r.is_suspicious)
    fn = sum(1 for p, r in zip(poisoned_products, results) if p.is_poisoned and not r.is_suspicious)
    tn = sum(1 for p, r in zip(poisoned_products, results) if not p.is_poisoned and not r.is_suspicious)
    
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    accuracy = (tp + tn) / len(results)
    
    print(f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                        CONFUSION MATRIX                                â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                                                                        â•‘
    â•‘                      â”‚  Predicted     â”‚  Predicted     â”‚               â•‘
    â•‘                      â”‚  POISONED      â”‚  CLEAN         â”‚               â•‘
    â•‘      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â•‘
    â•‘      Actually        â”‚                â”‚                â”‚               â•‘
    â•‘      POISONED        â”‚  TP: {tp:4d}      â”‚  FN: {fn:4d}      â”‚               â•‘
    â•‘      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â•‘
    â•‘      Actually        â”‚                â”‚                â”‚               â•‘
    â•‘      CLEAN           â”‚  FP: {fp:4d}      â”‚  TN: {tn:4d}      â”‚               â•‘
    â•‘                                                                        â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                        KEY METRICS                                     â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                                                                        â•‘
    â•‘      PRECISION:  {precision*100:5.1f}%   (Of flagged items, how many are      â•‘
    â•‘                           actually poisoned?)                          â•‘
    â•‘                                                                        â•‘
    â•‘      RECALL:     {recall*100:5.1f}%   (Of poisoned items, how many did       â•‘
    â•‘                           we catch?)                                   â•‘
    â•‘                                                                        â•‘
    â•‘      F1 SCORE:   {f1*100:5.1f}%   (Harmonic mean - overall effectiveness)  â•‘
    â•‘                                                                        â•‘
    â•‘      ACCURACY:   {accuracy*100:5.1f}%   (Overall correct classifications)     â•‘
    â•‘                                                                        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("    Per-Attack Detection Rates:")
    print("    " + "â”€" * 50)
    
    attack_detection = {}
    for p, r in zip(poisoned_products, results):
        if p.is_poisoned:
            ptype = p.poison_type
            if ptype not in attack_detection:
                attack_detection[ptype] = {"detected": 0, "total": 0}
            attack_detection[ptype]["total"] += 1
            if r.is_suspicious:
                attack_detection[ptype]["detected"] += 1
    
    for attack, data in attack_detection.items():
        rate = data["detected"] / data["total"] if data["total"] > 0 else 0
        bar = "â–ˆ" * int(rate * 20) + "â–‘" * (20 - int(rate * 20))
        print(f"      {attack:25s} [{bar}] {rate*100:5.1f}%")
    
    section_break("CONCLUSION")
    
    # =========================================================================
    # CONCLUSION
    # =========================================================================
    
    print("""
    ğŸ¯ CONCLUSION
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    KEY TAKEAWAYS:
    
    1. SILENT DATA POISONING IS A REAL THREAT
       â€¢ AI systems learn from user-provided data
       â€¢ Attacks can be invisible to human reviewers
       â€¢ Real-world impact: biased rankings, fraud, manipulation
    
    2. MULTI-LAYER DEFENSE IS ESSENTIAL
       â€¢ No single defense catches all attacks
       â€¢ Different attacks require different detectors
       â€¢ "Defense in Depth" provides robust protection
    
    3. MEASURABLE RESULTS
       â€¢ Precision: {precision*100:.1f}% - Low false alarm rate
       â€¢ Recall: {recall*100:.1f}% - High detection rate
       â€¢ F1 Score: {f1*100:.1f}% - Strong overall performance
    
    4. PRACTICAL IMPACT
       â€¢ Search results protected from manipulation
       â€¢ Users see genuine products, not boosted fakes
       â€¢ Platform integrity maintained
    
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    FUTURE WORK:
    â€¢ Neural embedding-based detection (transformers)
    â€¢ Real-time streaming defense
    â€¢ Adversarial training for robustness
    â€¢ Cross-platform attack detection
    
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
                        Thank you for watching!
    
                        Project: Marketplace Poisoning Shield
                        Author:  Tanish Gupta
                        Course:  Intro to AI Security
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)


if __name__ == "__main__":
    main()
